
https://www.alibabacloud.com/help/zh/doc-detail/65683.htm?spm=a2c63.p38356.b99.21.4b753a9fXOb9TN

大数据使用场景
E-MapReduce产品当前主要满足企业的以下大数据场景：

批处理场景
该场景对磁盘吞吐和网络吞吐要求高，处理的数据量也大，但对数据处理的实时性要求不高，您可选用MapReduce、Pig、Spark组件。该场景对内存要求不高，选型时您需要重点关注作业对CPU和内存的需求，以及Shuffle对网络的需求。

Ad-Hoc查询
数据科学家或数据分析师使用即席查询工具检索数据。该场景对查询实时性、磁盘吞吐和网络吞吐要求高，您可选用E-MapReduce的Impala和Presto组件。该场景对内存要求高，选型时需要考虑数据和并发查询的数量。

流式计算、高网络吞吐和计算密集型场景
选用E-MapReduce Flink、Spark Streaming和Storm组件。

消息队列
该场景对磁盘吞吐和网络吞吐要求高，并且内存消耗大，存储不依赖于HDFS，您可选用E-MapReduce Kafka。为避免对Hadoop造成影响，E-MapReduce将Kafka与Hadoop分为两个集群。

数据冷备场景
该场景对计算和磁盘吞吐要求不高，但要求冷备成本低，推荐使用EMR D1实例做数据冷备，D1本地盘实例存储成本为0.003$/月/GB。

E-MapReduce节点
E-MapReduce节点有三种实例类型：主实例（Master）、核心实例（Core）和计算实例（Task）。

E-MapReduce存储可以采用高效云盘、本地盘、SSD云盘和SSD本地盘。磁盘性能为SSD本地盘 > SSD云盘 > 本地盘 > 高效云盘。

E-MapReduce底层存储支持OSS（仅标准型OSS）和HDFS。相对于HDFS，OSS的数据可用性更高（99.99999999%），HDFS的数据可用性由云盘或本地盘存储的可靠性来保证。

存储价格大致估算如下：

本地盘实例存储为0.003$/GB/月
OSS标准型存储为0.02$/GB/月
高效云盘存储为0.05$/GB/月
SSD云盘存储为0.143$/GB/月
E-MapReduce选型
Master节点选型

Master节点主要部署Hadoop的Master进程，例如，NameNode和ResourceManager等。

生产集群建议打开高可用HA，E-MapReduce的HDFS、YARN、Hive和HBase等组件均已实现HA。生产集群建议在创建集群的硬件配置步骤开启高可用。如果购买时未开启高可用，集群将无法在后续使用过程中开启高可用功能。

Master节点主要用来存储HDFS元数据和组件Log文件，属于计算密集型，对磁盘IO要求不高。HDFS元数据存储在内存中，建议根据文件数量选择16GB以上内存空间。

Core节点选型

Core节点主要用来存储数据和执行计算，运行DataNode和Nodemanager。

HDFS（3 备份）数据量大于60TB，建议采用本地盘实例（ECS.d1，ECS.d1NE），本地盘的磁盘容量为：（CPU核数/2）*5.5TB*实例数量。例如，购买4台8核D1实例，磁盘容量为：8/2*5.5*4 台=88TB。因为HDFS采用3备份，所以本地盘实例最少购买3台，考虑到数据可靠性和磁盘损坏因素，建议最少购买4台。

HDFS数据量小于60TB，可以考虑高效云盘和SSD云盘。

Task节点选型

Task节点主要用来补充Core节点CPU和内存计算能力的不足，节点并不存储数据，也不运行DataNode。您可根据CPU和内存需求来估算实例个数。